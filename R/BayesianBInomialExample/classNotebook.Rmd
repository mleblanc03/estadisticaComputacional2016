---
title: "Entiendiendo la inferencia bayesiana desde un punto de vista computacional"
output:
  html_document: default
  html_notebook: default
---

Hoy vamos a entender como funciona la inferencia de forma muy fácil. Supongamos el siguiente escenario: 

![](./images/cointoss.png){#im1 width=250px height=350px}


Supongamos que tenemos la siguiente muestra de datos....

```{r}
X <- data.frame(
  toss = c(1,1,1,1,1,1,1,0,0,1,1,1,1,0,1,0,1,1,1,0,1,1,1,1,1,0,1,0,1,0,1,0,1,1,0,1,0,1,0,1,0,1,1,1,0,1,1,1,0,1)
)
X
```
 
Vamos a hacer un análisis bayesiano para ver cuál de estas columnas es sesgada.
 
 
```{r}
mean(X[[1]])
```


## El modelo

Una muestra de tamaño $n$ de lanzamientos de moneda se modela con una variable aleatoria Bernoulli $\mathrm{Ber}(n, \Theta)$ donde el parámetro desconocido es $\theta$. Por lo tanto, el **modelo** es 
$$ P(X_i = 1 | \Theta = \theta) = \theta $$
Nuestros datos son el vector de observaciones
$$ X=(X_1, X_2, ... , X_n) $$
Los valores que observamos con la muestra es $x=(x_1, ..., x_n)=$`toss`.

Recuerden como definimos la **función de verosimilitud**.
$$ \mathrm{likelihood}(\theta;X) = P(X=x | \Theta = \theta) = \prod_{i=1}^n P(X_i = x_i | \Theta = \theta) = \theta^{\#1's}(1-\theta)^{\#0's} = \theta^{\sum x_i}(1-\theta)^{n - \sum x_i}$$
Por razones numéricas que van a quedar claras más adelante, no nos gusta trabajar con la verosimilitud sino con la log-versomilitud, por lo que nos queda
$$ \mathrm{loglikelihood}(\theta;X) = (\sum x_i)log(\theta) + (n - \sum x_i)\log(1-\theta) $$

## Distribución *a priori*

Tenemos que modelar nuestra creencia previa sobre $\Theta$. La costumbre en estadística para modelar conocimiento sobre probabilidades es usar una distribución Beta. Por ejemplo vamos a ver gráficas para distintos valores de theta

```{r}
library(ggplot2)
ggplot(data.frame(theta = c(0,1)), aes(theta)) + 
  stat_function(fun = dbeta, args = list(shape1 = .5, shape2 = .5), aes(colour = "a=.5; b=.5")) +
  stat_function(fun = dbeta, args = list(shape1 = 2.5, shape2 = 1.5), aes(colour = "a=2.5; b=1.5")) +
  stat_function(fun = dbeta, args = list(shape1 = 1.5, shape2 = 2.5), aes(colour = "a=1.5; b=2.5")) +
  stat_function(fun = dbeta, args = list(shape1 = 2, shape2 = 2), aes(colour = "a=2; b=2")) + ylab("density")
```


En este caso, vamos a suponer inicialmente que la moneda es justa, vamos a tomar parámetros $(0.5, 0.5)$. Así que nuestra función apriori es (recuerda que solo nos importa proporcional):

$$ \mathrm{prior}(\theta) = \theta^{-.5}(1-\theta)^{-.5} / \mathrm{Beta}(-.5,-,5) \propto \theta^{-.5}(1-\theta)^{-.5}  $$

Al igual que con la verosimilitud, numéricamente conviene usar el logaritmo

$$ \mathrm{loprior}(\theta) = -.5\log(\theta) -.5\log(1-\theta) + K$$
Aquí $K= - \mathrm{Beta}(-.5,-.5)$ es una constante que podremos ingorar totalmente.

## Distribución *a posteriori*

La distribución posterior es 
$$
f_{\Theta|X}({\theta | X=x}) \propto ~ \mathrm{likelihood}*\mathrm{prior} \propto \theta^{\sum x_i-.5}(1-\theta)^{n - \sum x_i -.5} 
$$
Para la progaamción solo vamos a necesitar la versión logaritmica de esta función
$$
\log(f_{\Theta|X}({\theta | X=x})) = \mathrm{loglikelihood}+\mathrm{logprior} 
$$
## Diseño del MCMC

El diseño de MCMC es bastante directo. Vamos a usar random walk metropolis. El tamaño de brinco lo vamos a elegir arbitrariamente inicialmente. Con lo único que hay que ser cuidadoso es que el algoritmo **Random-Walk metropolis** dice

1. Define una función objetivo $g$ de la cual quieres simular. En este caso 
$$g(\theta) = f_{\Theta|X}(\theta;X=x) $$
2. Define una semilla $\theta_0$ y un tamaño de brinco $\tau$ para el algoritmo. Es necesario que $g(\theta) > 0$ para que el procedimiento no falle.
3. Para $i=0,1,2,...$
    + Genera un candidato $\eta \sim N(\theta_i, \sigma)$
    + Simula $U \sim \mathrm{Unif}(0,1)$. Si $U \leq g(\eta)/g(\theta_i)$ entonces pon $\theta_{i+1} = \eta$ y pasa a la siguiente iteracíon, de lo contrario, genera un nuevo candidato $\eta$ y un nuevo $\eta$ hasta que se cumpla la condición. El propósito de este paso es aceptar al candidato $\eta$ con probabilidad $\min\{1, g(\eta)/g(\theta_i)\}$.


Como vamos a trabajar con las funciones logarítmicas vamos a  reemplazar la condición po
$$ \log(U) \leq \log(g(\eta)) - \log(g(\theta_i)) $$
De esta manera se garantiza que no haya problemas computacioales. Esto es fundamental cuando hay problemas más grandes.


## Simulación

Vamos a poner $\theta_0 = .5$ y $\sigma = .1$. A continuación se define el archivo de `C++` que hace la simulación de Metropolis-Hastings. El algoritmo de Random-Walk Metropolis está contenido en la función `run_mcmc` que recibe los datos y el número de simulaciones y regresa la simulación de la longitud deseada.

```{r engine='Rcpp'}
#include <Rcpp.h>
#include <iostream>
using namespace Rcpp;
using namespace std;

// [[Rcpp::export]]
double loglikelihood(double theta, NumericVector toss) {
  double sumx = sum(toss);
  int n = toss.size();
  return sumx*log(theta) + (n-sumx)*log(1-theta);
}

// [[Rcpp::export]]
double logprior(double theta, double prior_a, double prior_b) {
  return (prior_a-1)*log(theta) + (prior_b-1)*log(1-theta);
}

double logposterior(double theta, NumericVector toss, double prior_a, double prior_b) {
  return loglikelihood(theta, toss) + logprior(theta, prior_a, prior_b);
}


// [[Rcpp::export]]
NumericVector run_mcmc(
    NumericVector toss, 
    int n_sim, 
    double theta_0, 
    double jump_size = .5, 
    double prior_a=-.5, 
    double prior_b=-.5) {
  //
  NumericVector sim(n_sim + 1); 
  double U, eta;
  bool test;
  //
  sim[0] = theta_0;
  for (int i=0; i < n_sim; i++) {
    do {
      eta = (rnorm(sim[i], jump_size))[0];
      U = (runif(1))[0]; 
      if (eta < 0 or eta > 1) {
        test = false; // siempre revisen si estan en el espacio parametral
      } else {
        test = log(U) > logposterior(eta, toss, prior_a, prior_b) - logposterior(sim[i], toss, prior_a, prior_b); 
      }
    } while (test);
    sim[i + 1] = eta;
  }
  return sim;
}
```

Observemos como funciona
```{r}
loglikelihood(.5, X$toss)

```
```{r}
logprior(.3, shape1 = .1,  shape2 = .1)
```


```{r}
run_mcmc(
  toss = X$toss,
  n_sim = 10,
  theta_0 = .5,
  jump_size = .1,
  prior_a = .2,
  prior_b = .2
)
```


## Algunos diagnósticos




## Usar la simulación para obtener intervalos de probabilidad y el estimador de moda






